<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>üåü ZenBot - Ayurvedic AI with Emotion Radar</title>
  <link href="https://fonts.googleapis.com/css2?family=Quicksand:wght@500&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Quicksand', sans-serif;
      background: linear-gradient(to right, #0f0c29, #302b63, #24243e);
      color: #fff;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 20px;
    }
    h1 { color: #ff6ec4; margin-bottom: 10px; }
    .chat-box {
      width: 90%;
      max-width: 700px;
      background: rgba(0, 0, 0, 0.7);
      border-radius: 16px;
      padding: 20px;
      box-shadow: 0 0 20px rgba(255, 110, 196, 0.5);
      margin-top: 20px;
    }
    .messages {
      max-height: 400px;
      overflow-y: auto;
      margin-bottom: 20px;
    }
    .bubble {
      padding: 12px 16px;
      border-radius: 20px;
      margin: 8px 0;
      max-width: 80%;
      white-space: pre-line;
    }
    .user {
      background: #6a11cb;
      align-self: flex-end;
      color: white;
      margin-left: auto;
    }
    .bot {
      background: #2575fc;
      align-self: flex-start;
      color: white;
      margin-right: auto;
    }
    form {
      display: flex;
      gap: 10px;
    }
    input[type="text"] {
      flex-grow: 1;
      padding: 10px;
      border-radius: 10px;
      border: none;
      font-size: 1rem;
    }
    button {
      background-color: #ff6ec4;
      color: white;
      padding: 10px 20px;
      border: none;
      font-size: 1rem;
      border-radius: 10px;
      cursor: pointer;
    }
    .emotion {
      font-size: 1.2rem;
      margin-top: 10px;
      color: #00ffd5;
    }
    .webcam-container {
      margin-top: 20px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    .toggle-btn {
      margin-top: 10px;
      background-color: #00ffd5;
      color: black;
      font-weight: bold;
    }
  </style>
</head>
<body>
  <h1>üåø Ayurv: Your Ayurvedic Mental Health Companion</h1>

  <!-- Emotion Display -->
  <div class="emotion">üå°Ô∏è Detected Emotion: <strong id="emotion">{{ emotion }}</strong></div>

  <!-- Toggle Emotion Button -->
  <div class="webcam-container">
    <form action="/toggle_emotion" method="post">
      <button type="submit" class="toggle-btn">
        {{ 'Disable Emotion Detection' if emotion_on else 'Enable Emotion Detection' }}
      </button>
    </form>
  </div>

  <!-- Chatbox -->
  <div class="chat-box">
    <div class="messages">
      {% for m in messages %}
        <div class="bubble user">üßë {{ m.user }}</div>
        <div class="bubble bot">ü§ñ {{ m.bot | safe }}</div>
      {% endfor %}
    </div>
<!-- Chat Input Row -->
<form id="chatForm" action="/chat" method="post" enctype="multipart/form-data">
  <input type="text" id="textInput" name="user_input" placeholder="Ask something spiritual..." required>
  <button type="submit">Send</button>
  <button type="button" onclick="startRecording()">üé§</button>
  <button type="button" onclick="playLastResponse()">üîä</button>
</form>
  </div>

  <!-- Poll emotion -->
  <script>
    setInterval(() => {
      fetch('/get_emotion')
        .then(res => res.json())
        .then(data => {
          document.getElementById("emotion").textContent = data.emotion;
        });
    }, 2000);
  </script>
<script>
let mediaRecorder, audioChunks = [];

function startRecording() {
  navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
    mediaRecorder = new MediaRecorder(stream);
    mediaRecorder.start();
    audioChunks = [];

    mediaRecorder.ondataavailable = event => {
      audioChunks.push(event.data);
    };

    mediaRecorder.onstop = () => {
      const blob = new Blob(audioChunks, { type: 'audio/wav' });
      const formData = new FormData();
      formData.append('audio', blob, 'voice.wav');

      fetch('/transcribe', { method: 'POST', body: formData })
        .then(response => response.json())
        .then(data => {
          document.getElementById('textInput').value = data.text;
        });
    };

    setTimeout(() => mediaRecorder.stop(), 5000); // auto-stop after 5s
  });
}

function playLastResponse() {
  const lastBotBubble = document.querySelector('.bubble.bot:last-of-type');
  if (!lastBotBubble) return;

  const text = lastBotBubble.innerText.replace("ü§ñ ", "");
  const formData = new FormData();
  formData.append('text', text);

  fetch('/speak', { method: 'POST', body: formData })
    .then(response => response.blob())
    .then(blob => {
      const audio = new Audio(URL.createObjectURL(blob));
      audio.play();
    });
}
</script>
<script>
  let recognizing = false;
  let recognition;

  function startRecording() {
    if (!('webkitSpeechRecognition' in window)) {
      alert("Speech recognition not supported in this browser.");
      return;
    }

    if (!recognition) {
      recognition = new webkitSpeechRecognition();
      recognition.lang = 'en-US';
      recognition.continuous = false;
      recognition.interimResults = false;

      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        document.getElementById("textInput").value = transcript;
        recognizing = false;
      };

      recognition.onerror = (event) => {
        console.error("Speech recognition error:", event.error);
        recognizing = false;
      };

      recognition.onend = () => {
        recognizing = false;
      };
    }

    if (!recognizing) {
      recognition.start();
      recognizing = true;
      console.log("üéôÔ∏è Recording started...");
    } else {
      recognition.stop();
      recognizing = false;
      console.log("üõë Recording stopped.");
    }
  }
</script>
<script>
  let isSpeaking = false;
  let utterance = null;

  function playLastResponse() {
    const lastBotMessages = document.querySelectorAll(".bubble.bot");
    if (lastBotMessages.length === 0) return;

    const lastMessage = lastBotMessages[lastBotMessages.length - 1].innerText;

    if (!isSpeaking) {
      utterance = new SpeechSynthesisUtterance(lastMessage);
      utterance.lang = 'en-US';
      utterance.rate = 1;
      utterance.onend = () => {
        isSpeaking = false;
      };
      speechSynthesis.speak(utterance);
      isSpeaking = true;
    } else {
      speechSynthesis.cancel();
      isSpeaking = false;
    }
  }
</script>

</body>
</html>
